<?xml version="1.0" encoding="UTF-8"?>
<!--Thu Mar 14 17:25:37 2013-->
<configuration>
  <property>
    <name>ipc.client.idlethreshold</name>
    <value>8000</value>
  </property>
  <property>
    <name>hadoop.proxyuser.hive.hosts</name>
    <value>hadsad01.homedepot.com</value>
  </property>
  <property>
    <name>ipc.client.connect.max.retries</name>
    <value>50</value>
  </property>
  <property>
    <name>hadoop.proxyuser.hcat.groups</name>
    <value>users</value>
  </property>
  <property>
    <name>webinterface.private.actions</name>
    <value>false</value>
  </property>
  <property>
    <name>fs.trash.interval</name>
    <value>1440</value>
  </property>
  <property>
    <name>fs.checkpoint.dir</name>
    <value>/nodedirs/snn</value>
  </property>
  <property>
    <name>hadoop.proxyuser.hive.groups</name>
    <value>users</value>
  </property>
  <property>
    <name>ipc.client.connection.maxidletime</name>
    <value>30000</value>
  </property>
  <property>
    <name>fs.checkpoint.edits.dir</name>
    <value>/nodedirs/snn</value>
  </property>
  <property>
    <name>hadoop.proxyuser.hcat.hosts</name>
    <value>hadsad01.homedepot.com</value>
  </property>
  <property>
    <name>fs.checkpoint.size</name>
    <value>0.5</value>
  </property>
  <property>
    <name>io.serializations</name>
    <value>org.apache.hadoop.io.serializer.WritableSerialization</value>
  </property>
  <property>
    <name>fs.checkpoint.period</name>
    <value>21600</value>
  </property>
  <property>
    <name>fs.default.name</name>
    <!-- This value MUST be a fully qualified domain name! -->
    <value>hdfs://hadmad01.homedepot.com:8020</value>
    <description>The name of the default file system.  A URI whose
  scheme and authority determine the FileSystem implementation.  The
  uri's scheme determines the config property (fs.SCHEME.impl) naming
  the FileSystem implementation class.  The uri's authority is used to
  determine the host, port, etc. for a filesystem.</description>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>/tmp/hadoop-${user.name}</value>
    <final>true</final>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>io.file.buffer.size</name>
    <value>131072</value>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>io.compression.codecs</name>
    <value>org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec,org.apache.hadoop.io.compress.BZip2Codec</value>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>io.compression.codec.lzo.class</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>io.sort.factor</name>
    <value>64</value>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>io.sort.mb</name>
    <value>256</value>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>fs.inmemory.size.mb</name>
    <value>200</value>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>hadoop.proxyuser.tomcat.hosts</name>
    <value>*</value>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>hadoop.proxyuser.tomcat.groups</name>
    <value>*</value>
    <!--This property is taken from the OLD configurations-->
  </property>
</configuration>
