<?xml version="1.0" encoding="UTF-8"?>
<!--Thu Mar 14 17:25:37 2013-->
<configuration>
  <property>
    <name>dfs.datanode.du.pct</name>
    <value>0.85f</value>
  </property>
  <property>
    <name>dfs.datanode.http.address</name>
    <value>0.0.0.0:50075</value>
  </property>
  <property>
    <name>dfs.datanode.failed.volumes.tolerated</name>
    <value>0</value>
  </property>
  <property>
    <name>dfs.http.address</name>
    <value>hadmad01.homedepot.com:50070</value>
  </property>
  <property>
    <name>dfs.hosts.exclude</name>
    <value>/etc/hadoop/dfs.exclude</value>
  </property>
  <property>
    <name>dfs.datanode.kerberos.principal</name>
    <value>dn/_HOST@EXAMPLE.COM</value>
  </property>
  <property>
    <name>dfs.secondary.https.port</name>
    <value>50490</value>
  </property>
  <property>
    <name>dfs.secondary.http.address</name>
    <value>hadmad02.homedepot.com:50090</value>
  </property>
  <property>
    <name>dfs.namenode.keytab.file</name>
    <value>/etc/security/keytabs/nn.service.keytab</value>
  </property>
  <property>
    <name>dfs.block.local-path-access.user</name>
    <value>hbase</value>
  </property>
  <property>
    <name>dfs.datanode.ipc.address</name>
    <value>0.0.0.0:8010</value>
  </property>
  <property>
    <name>dfs.secondary.namenode.kerberos.principal</name>
    <value>nn/_HOST@EXAMPLE.COM</value>
  </property>
  <property>
    <name>dfs.web.ugi</name>
    <value>gopher,gopher</value>
  </property>
  <property>
    <name>dfs.cluster.administrators</name>
    <value>hdfs</value>
  </property>
  <property>
    <name>dfs.web.authentication.kerberos.keytab</name>
    <value>/etc/security/keytabs/spnego.service.keytab</value>
  </property>
  <property>
    <name>dfs.heartbeat.interval</name>
    <value>3</value>
  </property>
  <property>
    <name>dfs.umaskmode</name>
    <value>077</value>
  </property>
  <property>
    <name>ipc.server.max.response.size</name>
    <value>5242880</value>
  </property>
  <property>
    <name>dfs.https.address</name>
    <value>hadmad01.homedepot.com:50470</value>
  </property>
  <property>
    <name>dfs.replication.max</name>
    <value>50</value>
  </property>
  <property>
    <name>dfs.datanode.socket.write.timeout</name>
    <value>0</value>
  </property>
  <property>
    <name>dfs.namenode.kerberos.https.principal</name>
    <value>host/_HOST@EXAMPLE.COM</value>
  </property>
  <property>
    <name>dfs.hosts</name>
    <value>/etc/hadoop/dfs.include</value>
  </property>
  <property>
    <name>dfs.https.port</name>
    <value>50470</value>
  </property>
  <property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.blockreport.initialDelay</name>
    <value>120</value>
  </property>
  <property>
    <name>dfs.access.time.precision</name>
    <value>0</value>
  </property>
  <property>
    <name>dfs.namenode.kerberos.principal</name>
    <value>nn/_HOST@EXAMPLE.COM</value>
  </property>
  <property>
    <name>dfs.datanode.data.dir.perm</name>
    <value>750</value>
  </property>
  <property>
    <name>dfs.secondary.namenode.kerberos.https.principal</name>
    <value>host/_HOST@EXAMPLE.COM</value>
  </property>
  <property>
    <name>dfs.block.access.token.enable</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.datanode.keytab.file</name>
    <value>/etc/security/keytabs/dn.service.keytab</value>
  </property>
  <property>
    <name>ipc.server.read.threadpool.size</name>
    <value>5</value>
  </property>
  <property>
    <name>dfs.datanode.address</name>
    <value>0.0.0.0:50010</value>
  </property>
  <property>
    <name>dfs.secondary.namenode.keytab.file</name>
    <value>/etc/security/keytabs/nn.service.keytab</value>
  </property>
  <property>
    <name>dfs.safemode.threshold.pct</name>
    <value>1.0f</value>
  </property>
  <property>
    <name>dfs.replication</name>
    <value>3</value>
    <description>Default block replication.
  The actual number of replications can be specified when the file is created.
  The default is used if replication is not specified in create time.</description>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>dfs.name.dir</name>
    <value>/opt/hd/db/data/01/dfs/nn,/opt/hd/db/data/02/dfs/nn,/mnt/hd/db/data/04/dfs/nn</value>
    <final>true</final>
    <description>Ideally should be 2 local volumes and 1 mounted volume</description>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>dfs.data.dir</name>
    <value>/opt/hd/db/data/01/dfs/dn,/opt/hd/db/data/02/dfs/dn,/opt/hd/db/data/03/dfs/dn,/opt/hd/db/data/04/dfs/dn,/opt/hd/db/data/05/dfs/dn</value>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>dfs.block.size</name>
    <value>134217728</value>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>dfs.namenode.handler.count</name>
    <value>10</value>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>dfs.datanode.handler.count</name>
    <value>10</value>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>dfs.permissions.supergroup</name>
    <value>hadoop</value>
    <final>true</final>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>dfs.permissions</name>
    <value>true</value>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>fs.checkpoint.dir</name>
    <value>/opt/hd/db/data/03/dfs/snn</value>
    <final>true</final>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>fs.trash.interval</name>
    <value>1440</value>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>dfs.datanode.max.xcievers</name>
    <value>6144</value>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>dfs.datanode.du.reserved</name>
    <value>53687091200</value>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>dfs.namenode.plugins</name>
    <value>org.apache.hadoop.thriftfs.NamenodePlugin</value>
    <description>Comma-separated list of namenode plug-ins to be activated.</description>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>dfs.datanode.plugins</name>
    <value>org.apache.hadoop.thriftfs.DatanodePlugin</value>
    <description>Comma-separated list of datanode plug-ins to be activated.</description>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>dfs.thrift.address</name>
    <value>0.0.0.0:10090</value>
    <!--This property is taken from the OLD configurations-->
  </property>
  <property>
    <name>dfs.balance.bandwidthPerSec</name>
    <value>100000000</value>
    <!--This property is taken from the OLD configurations-->
  </property>
</configuration>
